#!/bin/bash

# Example of usage:
# export OPENAI_API_KEY
# export PEN_ environment variables
# openai-complete.sh

sn="$(basename "$0")"

case "$sn" in
    ai21-complete.sh) {
        completer_sn=pen-ai21
        : "${AIX_API_KEY:="$PEN_LM_KEY"}"
        export AIX_API_KEY

        : "${PEN_MODEL:="j1-jumbo"}"
        : "${PEN_MODEL:="j1-large"}"
    }
    ;;

    aix-complete.sh) {
        completer_sn=pen-aix
        : "${AIX_API_KEY:="$PEN_LM_KEY"}"
        export AIX_API_KEY

        : "${PEN_MODEL:="GPT-J-6B"}"
    }
    ;;

    hf-complete.sh) {
        completer_sn=pen-hf
        : "${HF_API_KEY:="$PEN_LM_KEY"}"
        export HF_API_KEY

        : "${PEN_MODEL:="gpt2"}"
    }
    ;;

    nlpcloud-complete.sh) {
        completer_sn=pen-nlpcloud
        : "${NLPCLOUD_API_KEY:="$PEN_LM_KEY"}"
        export NLPCLOUD_API_KEY

        : "${PEN_MODEL:="gpt-j"}"
        : "${PEN_MODEL:="gpu/gpt-j"}"
    }
    ;;

    openai-complete.sh|openai-*|*) {
        completer_sn=pen-openai
        : "${OPENAI_API_KEY:="$PEN_LM_KEY"}"
        export OPENAI_API_KEY

        # Default for OpenAI is davinci
        : "${PEN_MODEL:="davinci"}"
        : "${PEN_MODEL:="curie"}"
    }
    ;;
esac

p () {
    {
        i=1
        while [ "$i" -lt "$#" ]; do
            eval ARG=\${$i}
            printf -- "%s " "$ARG"
            i=$((i + 1))
        done
        eval ARG=\${$i}
        printf -- "%s" "$ARG"
    } | sed 's/\\n/\n/g' | pen-restore-chars
}

openai_results_split() {
    completions_fp="$1"
    test -f "$completions_fp" || exit 1

    completions_fp="$(realpath "$completions_fp")"

    td="$(mktemp -t "results_$(date-ts-hr)_XXXXX" -d -p ~/.pen/results)"

    cd "$td"

    if test "$PEN_N_COMPLETIONS" = 1; then
        tail -c "+$(( PEN_COLLECT_FROM_POS + 1 ))" "$completions_fp" > response.txt
    elif cat "$completions_fp" | grep -q -P '^===== Completion [0-9]+ =====$'; then
        csplit -f splitfile_ -z "$completions_fp" "/^===== Completion [0-9]\\+ =====$/" '{*}' &>/dev/null
        for fp in *; do
            sed -i 1d "$fp"
            tail -c "+$(( PEN_COLLECT_FROM_POS + 1 ))" "$fp" | sponge "$fp"
        done
    else
        cat "$completions_fp" > splitfile_0.txt
    fi

    echo "$td"
}

nlpcloud_results_split() {
    completions_fp="$1"
    test -f "$completions_fp" || exit 1

    completions_fp="$(realpath "$completions_fp")"

    td="$(mktemp -d)"

    cd "$td"

    if cat "$completions_fp" | grep -q -P '^--------------$'; then
        csplit -f splitfile_ -z "$completions_fp" "/^--------------$/" '{*}' &>/dev/null
        for fp in *; do
            sed -i 1d "$fp"
            # printf -- "%s" "$PEN_PROMPT$PEN_TRAILING_WHITESPACE"
            re="$(printf -- "%s" "$PEN_TRAILING_WHITESPACE" | sed -z 's/././g')"
            sed -i -z "s/^$re//" "$fp"
        done
    else
        cat "$completions_fp" > splitfile_0.txt
    fi

    echo "$td"
}

if test "$PEN_DEBUG" = "y"; then
    echo "PEN_USER_AGENT:\"$PEN_USER_AGENT\""
    echo "PEN_PROMPT:\"$PEN_PROMPT\""
    echo "PEN_CACHE:\"$PEN_CACHE\""
    echo "PEN_MODEL:\"$PEN_MODEL\""
    echo "PEN_BEST_OF:\"$PEN_BEST_OF\""
    echo "PEN_FLAGS:\"$PEN_FLAGS\""
    echo "PEN_APPROXIMATE_PROMPT_LENGTH:\"$PEN_APPROXIMATE_PROMPT_LENGTH\""
    echo "PEN_MIN_TOKENS:\"$PEN_MIN_TOKENS\""
    echo "PEN_MAX_TOKENS:\"$PEN_MAX_TOKENS\""
    echo "PEN_MIN_GENERATED_TOKENS:\"$PEN_MIN_GENERATED_TOKENS\""
    echo "PEN_MAX_GENERATED_TOKENS:\"$PEN_MAX_GENERATED_TOKENS\""
    echo "PEN_ENGINE_MIN_TOKENS:\"$PEN_ENGINE_MIN_TOKENS\""
    echo "PEN_ENGINE_MAX_TOKENS:\"$PEN_ENGINE_MAX_TOKENS\""
    echo "PEN_ENGINE_MAX_GENERATED_TOKENS:\"$PEN_ENGINE_MAX_GENERATED_TOKENS\""
    echo "PEN_STOP_SEQUENCE:\"$PEN_STOP_SEQUENCE\""
    echo "PEN_REPETITION_PENALTY:\"$PEN_REPETITION_PENALTY\""
    echo "PEN_TOP_P:\"$PEN_TOP_P\""
    echo "PEN_TOP_K:\"$PEN_TOP_K\""
    echo "PEN_N_COMPLETIONS:\"$PEN_N_COMPLETIONS\""
    echo "PEN_ENGINE_MAX_N_COMPLETIONS:\"$PEN_ENGINE_MAX_N_COMPLETIONS\""
    exit 1
fi

# tf_prompt="$(mktemp -t "lm_results_XXXXXX.txt" 2>/dev/null)"
# trap "rm \"$tf_prompt\" 2>/dev/null" 0

# Default for OpenAI is davinci
: "${PEN_MODEL:="davinci"}"
: "${PEN_MODEL:="curie"}"

test -n "$PEN_PROMPT" || {
    echo No prompt given
    exit 1
}

: "${PEN_MIN_TOKENS:="20"}"
: "${PEN_MAX_TOKENS:="60"}"
: "${PEN_ENGINE_MIN_TOKENS:="20"}"
: "${PEN_ENGINE_MAX_TOKENS:="60"}"
: "${PEN_TEMPERATURE:="0.8"}"
: "${PEN_TOP_P:="1"}"
: "${PEN_BEST_OF:="1"}"
: "${PEN_N_COMPLETIONS:="1"}"

export PEN_USER_AGENT
export PEN_LM_KEY
export PEN_MODEL
export PEN_FLAGS
export PEN_MIN_TOKENS
export PEN_MAX_TOKENS
export PEN_APPROXIMATE_PROMPT_LENGTH
export PEN_MIN_GENERATED_TOKENS
export PEN_MAX_GENERATED_TOKENS
export PEN_ENGINE_MIN_TOKENS
export PEN_ENGINE_MAX_TOKENS
export PEN_TEMPERATURE
export PEN_TOP_P
export PEN_TOP_K
export PEN_STOP_SEQUENCE
export PEN_REPETITION_PENALTY
export PEN_LENGTH_PENALTY
export PEN_CACHE
export PEN_MODE
export PEN_BEST_OF
export PEN_ENGINE_MAX_GENERATED_TOKENS
export PEN_ENGINE_MAX_N_COMPLETIONS
# Some backends strip whitespace. Recreate it.
export PEN_TRAILING_WHITESPACE

tf_response="$(mktemp -t "lm_results_XXXXXX.txt" 2>/dev/null)"
trap "rm \"$tf_response\" 2>/dev/null" 0

# This evaluates the newlines without trimming the prompt at the ends
IFS= read -rd '' PEN_PROMPT < <(p "$PEN_PROMPT");typeset -p PEN_PROMPT &>/dev/null

# This is designed to not trim whitespace from the ends of the stop sequence
IFS= read -rd '' PEN_STOP_SEQUENCE < <(p "$PEN_STOP_SEQUENCE");typeset -p PEN_STOP_SEQUENCE &>/dev/null

# Will it complain if PEN_STOP_SEQUENCE is empty?

case "$sn" in
    ai21-complete.sh) {
        "$completer_sn" > "$tf_response"
    }
    ;;

    aix-complete.sh) {
        "$completer_sn" > "$tf_response"
    }
    ;;

    hf-complete.sh) {
        "$completer_sn" > "$tf_response"
    }
    ;;

    nlpcloud-complete.sh) {
        "$completer_sn" > "$tf_response"
    }
    ;;

    openai-complete.sh|openai-*) {
        # TODO: Make a new completer

        # - BEST_OF
        # - TOP_K

        "$completer_sn" api \
            completions.create \
            -e "$PEN_MODEL" \
            -t "$PEN_TEMPERATURE" \
            -P "$PEN_TOP_P" \
            -M "$PEN_MAX_GENERATED_TOKENS" \
            -n "$PEN_N_COMPLETIONS" \
            --stop "$PEN_STOP_SEQUENCE" \
            -p "$PEN_PROMPT" > "$tf_response"
    }
    ;;

    *) {
        "$completer_sn" > "$tf_response"
    }
    ;;
esac

case "$sn" in
    nlpcloud-complete.sh) {
        export PEN_COLLECT_FROM_POS
        results_dir="$(nlpcloud_results_split "$tf_response")"
    }
    ;;

    *) {
        : "${PEN_COLLECT_FROM_POS:="$(cat "$tf_response" | wc -c)"}"

        export PEN_COLLECT_FROM_POS
        results_dir="$(openai_results_split "$tf_response")"
    }
    ;;
esac

# The API returns the entire prompt + completion
# Which seems a little bit wasteful.
# That may change.
# sp +/"^Echo" "$NOTES/ws/openai/api/glossary.txt"
# It's the openai cli which doesn't yet have an echo parameter

# jsonl output would be nice but jq is an extra dependency I don't want.
# Alternatively, can could make it linewise.

echo "$results_dir"

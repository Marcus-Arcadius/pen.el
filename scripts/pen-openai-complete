#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import openai
import os
import json

API_TOKEN = os.environ.get("OPENAI_API_KEY")
PEN_MODEL = os.environ.get("PEN_MODEL") or "davinci"
PEN_PROMPT = os.environ.get("PEN_PROMPT") or "Once upon a time"
PEN_MODE = os.environ.get("PEN_MODE")
PEN_TEMPERATURE = os.environ.get("PEN_TEMPERATURE") or "0.8"
PEN_STOP_SEQUENCES = os.environ.get("PEN_STOP_SEQUENCES") or ["\n"]
PEN_STOP_SEQUENCE = os.environ.get("PEN_STOP_SEQUENCE") or "\n"
PEN_LOGPROBS = os.environ.get("PEN_LOGPROBS") or "10"
PEN_N_COMPLETIONS = os.environ.get("PEN_LOGPROBS") or "2"
PEN_MAX_TOKENS = os.environ.get("PEN_MAX_TOKENS") or "15"
PEN_MAX_GENERATED_TOKENS = os.environ.get("PEN_MAX_GENERATED_TOKENS") or "5"
PEN_LOGIT_BIAS = os.environ.get("PEN_LOGIT_BIAS")
PEN_TRAILING_WHITESPACE = os.environ.get("PEN_TRAILING_WHITESPACE")

# int(PEN_LOGPROBS)

# Serialise the LOGIT_BIAS as json
# It needs to arrive as a python dict

# LOGIT_BIAS is not a big priority
# Besides, char-level models might make this completely redundant

# openai.Completion.create(
#      engine=PEN_MODEL,
#      prompt=PEN_PROMPT,
#      logprobs=int(PEN_LOGPROBS),
#      stop=PEN_STOP_SEQUENCE,
#      temperature=float(PEN_TEMPERATURE),
#      logit_bias={6342: -1})

from shanepy import *
myembed(globals(), locals())

cs = openai.Completion.create(
     n=int(PEN_N_COMPLETIONS),
     engine=PEN_MODEL,
     prompt=PEN_PROMPT,
     logprobs=int(PEN_LOGPROBS),
     stop=PEN_STOP_SEQUENCE,
     max_tokens=int(PEN_MAX_GENERATED_TOKENS),
     temperature=float(PEN_TEMPERATURE))['choices']

cs[0]['text']
cs[0]['logprobs']
cs[0]['logprobs']['text_offset']
cs[0]['logprobs']['token_logprobs']
cs[0]['logprobs']['tokens']
cs[0]['logprobs']['top_logprobs']
cs[0]['logprobs']['top_logprobs'][0]
cs[0]['logprobs']['top_logprobs'][0].keys()
cs[0]['logprobs']['top_logprobs'][0].values()
# json
# tv(str(cs[0]))
sps("jq . | vs", str(cs[0]))
sps("jq . | jq-showschema | vs", str(cs[0]))
# jq-showschema

cs[1]['text']
cs[1]['logprobs']

# Return probabilities
# 
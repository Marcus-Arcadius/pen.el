- Current Work
  - Construct/template the final prompt
    sp +/"finalprompt" "$HOME/source/git/semiosis/pen.el/pen.el"
  - Use emacs' prompts hash table to generate the csv
    This way the catalog will open instantaneously.
    - Delete prompts-details
      $MYGIT/semiosis/pen.el/scripts/prompts-details
  - Add functions to company-mode if they are specified as such
    sp +/";; TODO Add to company-mode completion functions" "$HOME/source/git/semiosis/pen.el/pen.el"
  - collation-postprocessor
    sp +/"collation-postprocessor" "$HOME/source/git/semiosis/pen.el/pen.el"
  - Send max-tokens temperature top-p to lm-complete as environment variables
    sp +/"max-tokens temperature top-p" "$HOME/source/git/semiosis/pen.el/pen.el"

- Features
  - stream into emacs
    - collect logprobs as text properties
      - And into the list of completions every time
  - Select error messages and ask what they mean
  - Correct spelling and grammar in conversations over =erc= and other =emacs= chat modes.
  - Encode where the text came from into the emacs buffer using emacs text properties
    - This is for =ink.el=
      - https://github.com/semiosis/ink.el

- Far future features
  - Build a database of NLP tasks and synchronize them (perhaps in the form of prompts)
    - Initially use GitHub
    - Later switch from merely prompts to include other sources
      - API calls
      - AWS Lambdas
  - Ratings for prompts / NLP tasks
    - Use Datomic
  - Retain all generations
    - Use Datomic